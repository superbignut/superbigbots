{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    当下的思路是先使用01 来对数据进行stdp预训练，训练的结果要满足对01数据可以达到比较好的分类\n",
    "\n",
    "    进而切换到更多数据，比如加入\"5\", 这里假设认为5 归属于1， 那么需要设计网络的权重更新，使得5\n",
    "\n",
    "    对应的脉冲输出可以不断的替代掉老的数据， 这里总感觉有一个buffer 的含义，\n",
    "\n",
    "    并且，对真实交互的数据的重要性要进行方法，这里可以体现在，reward上，也可以体现在 buffer的统计上\n",
    "\n",
    "    感觉本质上还是一个特征提取的操作\n",
    "\n",
    "    如果只使用原来的算法，很可能最开始的预训练的速度很慢，可以想办法加快一点，对stdp进行修改\n",
    "\n",
    "    1的脉冲次数 要小于0的次数很多， 这里怀疑可能跟 1 的图像面积小有关系\n",
    "\n",
    "    这里的面积的大小与出现的次数还没有关系\n",
    "\"\"\"\n",
    "import collections\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from SPAIC import spaic\n",
    "import torch.nn.functional as F\n",
    "from SPAIC.spaic.Learning.Learner import Learner\n",
    "from SPAIC.spaic.Library.Network_saver import network_save\n",
    "from SPAIC.spaic.Library.Network_loader import network_load\n",
    "from SPAIC.spaic.IO.Dataset import MNIST as dataset\n",
    "from SPAIC.spaic.IO.Dataset import CUSTOM_MNIST, NEW_DATA_MNIST\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_path = './log/test2'\n",
    "writer = SummaryWriter(log_path)\n",
    "\n",
    "for file in os.listdir(log_path):\n",
    "    os.remove(log_path + '/' + file) # 把和上一次的log清空\n",
    "\n",
    "# tensorboard.exe --logdir=./log/episode_reward\n",
    "\n",
    "root = './SPAIC/spaic/Datasets/MNIST'\n",
    "train_set = CUSTOM_MNIST(root, is_train=True) # 这里加一个mast 只要01\n",
    "test_set =CUSTOM_MNIST(root, is_train=False)\n",
    "new_data_set = NEW_DATA_MNIST(root, is_train=False) # 引入新的数据 包括012\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "node_num = 784\n",
    "label_num = 100 # 这里要不了这么多\n",
    "\n",
    "bat_size = 1\n",
    "\n",
    "\n",
    "train_loader = spaic.Dataloader(train_set, batch_size=bat_size, shuffle=False, drop_last=False)\n",
    "test_loader = spaic.Dataloader(test_set, batch_size=bat_size, shuffle=False)\n",
    "newdata_loader = spaic.Dataloader(new_data_set,batch_size=bat_size,shuffle=False)\n",
    "\n",
    "backend = spaic.Torch_Backend(device)\n",
    "backend.dt = 0.1\n",
    "run_time = 256 * backend.dt \n",
    "\n",
    "time_step = int(run_time / backend.dt)\n",
    "\n",
    "lr = 0.001 # stdp暂时不用学习率， 真实的学习率应该是体现在算法里面了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TestNet(spaic.Network):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = spaic.Encoder(num=node_num, time=run_time, coding_method='poisson', unit_conversion=0.6375) # 就是给发放速率乘了因子,from 论文\n",
    "\n",
    "        self.layer1 = spaic.NeuronGroup(label_num, model='lifstdp_ex') # stdp_ex 比 stdp_ih 多了一层阈值的衰减 \\tao_\\theta, 论文中有提到这个自适应的阈值\n",
    "        \n",
    "        self.layer2 = spaic.NeuronGroup(label_num, model='lifstdp_ih') # 维度都是100， \n",
    "\n",
    "        self.output = spaic.Decoder(num=label_num, dec_target=self.layer1, time=run_time, coding_method='spike_counts') # layer1作为了输出层, 兴奋次数作为输出\n",
    "\n",
    "        self.connection1 = spaic.Connection(self.input, self.layer1, link_type='full', weight=(np.random.rand(label_num, 784) * 0.3)) # 100 * 784\n",
    "        \n",
    "        self.connection2 = spaic.Connection(self.layer1, self.layer2, link_type='full', weight=np.diag(np.ones(label_num)) * 22.5   )\n",
    "        \n",
    "        self.connection3 = spaic.Connection(self.layer2, self.layer1, link_type='full', weight=( np.ones((label_num, label_num)) - np.diag(np.ones(label_num)) ) * (-120)) # 起到一个抑制的作用，除了1-1的前一个，侧向抑制，并起到竞争的效果\n",
    "\n",
    "        self._learner = Learner(algorithm='nearest_online_stdp', trainable=self.connection1, run_time=run_time) # 这里也只是训练 从输入到第一层的连接，其余层不变\n",
    "\n",
    "        self.reward = spaic.Reward(num=label_num, dec_target=self.layer1, coding_time=run_time, coding_method='environment_reward', dec_sample_step=1) # 采样频率是每个时间步一次\n",
    "        #\n",
    "        self.mon_weight = spaic.StateMonitor(self.connection1, 'weight', nbatch=-1)\n",
    "        \n",
    "        self.set_backend(backend)\n",
    "\n",
    "        self.buffer = [[],[]] # 0, 1 投票神经元的buffer\n",
    "\n",
    "        self.assign_label = None\n",
    "\n",
    "    def step(self, data, reward=1):\n",
    "\n",
    "        self.input(data) # 输入数据\n",
    "\n",
    "        self.reward(1) # 这里1，rstdp 退化为stdp 输入奖励 0 则不更新权重\n",
    "\n",
    "        self.run(run_time) # 前向传播\n",
    "\n",
    "        return self.output.predict # 输出 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TestNet() # 这里如果一个网络 不行，也可以考虑使用第二个网络进行辅助？\n",
    "\n",
    "im = None\n",
    "\n",
    "file_name = 'save/testidea' # 权重的保存文件\n",
    "buffer_name = 'buffer.pth' # buffer的保存文件\n",
    "\n",
    "train_num = 1000 # 800次的时候可以达到0.65的成功率 这里应该想办法怎么既能减小 训练次数又能 增大预训练的效率\n",
    "\n",
    "def TestNet_Init(flag='train'):\n",
    "    \"\"\"\n",
    "        这个函数完成对0 1数据的初始化操作， 也就是希望网路可以达到对0 1的初步分类作用\n",
    "        可以的话，最好把权重也保存一下，下次再使用的时候就不用再次训练了\n",
    "    \"\"\"\n",
    "    global im\n",
    "    if flag =='train':\n",
    "\n",
    "        print(\"开始预训练\")\n",
    "        for episode in range(1):\n",
    "            pbar = tqdm(total=len(train_loader))\n",
    "\n",
    "            for i, item in enumerate(train_loader):\n",
    "                data, label = item\n",
    "                output = agent.step(data)\n",
    "\n",
    "                agent.buffer[label[0]].append(output) # label[0]的第一个维度是batch\n",
    "                im = agent.mon_weight.plot_weight(time_id=-1, linewidths=0, linecolor='white',\n",
    "                            reshape=True, n_sqrt=int(np.sqrt(label_num)), side=28, im=im, wmax=1) #把权重 画出来 100 * 784 = 100 * 28 * 28\n",
    "                pbar.update()\n",
    "                if i > train_num:\n",
    "                    break #   \n",
    "        # network_save(Net=agent,filename='saveidea',save_weight=True)\n",
    "\n",
    "        agent.save_state(filename=file_name) # 这里需要手动删除保存的文件夹\n",
    "        torch.save(agent.buffer, buffer_name) # buffer 也需要保存起来\n",
    "\n",
    "    elif flag == 'load':\n",
    "        print(\"加载预训练数据和buffer\")\n",
    "        agent.state_from_dict(filename=file_name, device=device)\n",
    "        agent.buffer = torch.load(buffer_name)\n",
    "\n",
    "    assign_label_update() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label_update(newoutput=None, newlabel=None, weight=0):\n",
    "    # 如果没有新的数据输入，则就是对 assign_label 进行一次计算，否则 会根据权重插入新数据，进而计算\n",
    "    if newoutput != None:\n",
    "        agent.buffer[newlabel].append(newoutput)\n",
    "    avg_buffer = [sum(agent.buffer[i]) / len(agent.buffer[i]) for i in range(len(agent.buffer))] # sum_buffer 是一个求和之后 取平均的tensor  n * 1 * 100\n",
    "    # avg_buffer = [sum_buffer[i] / len(agent.buffer[i]) for i in range(len(agent.buffer))]\n",
    "    assign_label = torch.argmax(torch.cat(avg_buffer, 0), 0) # n 个1*100 的list在第0个维度合并 -> n*100的tensor, 进而在第0个维度比哪个更大, 返回一个1维的tensor， 内容是index，0-n， 目前是0和1\n",
    "    # 这里的 100 个 0 和1 也就代表了， 当前那个神经元 可以代表的 类别是什么\n",
    "    agent.assign_label = assign_label # 初始化结束\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_acc = []\n",
    "def TestNet_Eval(eval_num=1000):\n",
    "    # 这里测试一下对0和1的准确率\n",
    "    global im\n",
    "    right_predict = 0\n",
    "    \n",
    "    print(\"开始预测\")\n",
    "\n",
    "    with torch.no_grad(): # 这里存粹的测试，不会更新权重 没有 drop层 所以与使用 eval 是一样的效果\n",
    "        pbar = tqdm(total=len(test_loader))\n",
    "        for index, item in enumerate(test_loader):\n",
    "            data, label = item\n",
    "            output = agent.step(data)\n",
    "        \n",
    "            temp_cnt = [0 for _ in range(len(agent.buffer))]\n",
    "            # 这里的每一个输出[1,2,3,4,5...], 就像是在投票，由于每一个位置类别已经确定，现在，只需要把每个类别的投票的总次数加起来，即可\n",
    "            for i in range(len(agent.assign_label)):\n",
    "                temp_cnt[agent.assign_label[i]] += output[0, i] # 第一个维度是batch, \n",
    "\n",
    "            predict_label = torch.argmax(torch.tensor(temp_cnt))\n",
    "            # print(\"... \", label, predict_label)\n",
    "            if label[0] == predict_label:\n",
    "                right_predict += 1\n",
    "            eval_acc.append(right_predict / (1+index))\n",
    "            if index > eval_num:\n",
    "                break\n",
    "            pbar.update()\n",
    "    print(\" 总数为：\", eval_num+2 ,\" 预测成功为：\",right_predict)\n",
    "    plt.plot(eval_acc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nd_eval_acc = []\n",
    "\n",
    "right_predict = 0\n",
    "def ND_TestNet_Eval_And_Train(nd_eval_num = 1000):\n",
    "    # 从这里开始增加2 作为新数据，并把2 归属与 1 的label\n",
    "    global im, right_predict\n",
    "    \n",
    "    \n",
    "    print(\"新数据集测试与微调\")\n",
    "\n",
    "    pbar = tqdm(total=len(newdata_loader))\n",
    "    for index, item in enumerate(newdata_loader):\n",
    "        \n",
    "        data, label = item\n",
    "        print(label)\n",
    "        if label[0] != 0:\n",
    "            label[0] = 1 # 把2 也归为1\n",
    "        output = agent.step(data)\n",
    "        im = agent.mon_weight.plot_weight(time_id=-1, linewidths=0, linecolor='white',\n",
    "                            reshape=True, n_sqrt=int(np.sqrt(label_num)), side=28, im=im, wmax=1) #把权重 画出来 100 * 784 = 100 * 28 * 28\n",
    "\n",
    "        temp_cnt = [0 for _ in range(len(agent.buffer))]\n",
    "        # 这里的每一个输出[1,2,3,4,5...], 就像是在投票，由于每一个位置类别已经确定，现在，只需要把每个类别的投票的总次数加起来，即可\n",
    "        for i in range(len(agent.assign_label)):\n",
    "            temp_cnt[agent.assign_label[i]] += output[0, i] # 第一个维度是batch, \n",
    "\n",
    "        predict_label = torch.argmax(torch.tensor(temp_cnt))\n",
    "        # print(\"... \", label, predict_label)\n",
    "        if label[0] == predict_label:\n",
    "            right_predict += 1\n",
    "\n",
    "        # 这里要使用真实标签对数据对投票集进行补充或修改\n",
    "        assign_label_update(output, label[0], weight=0) # 权重的体现，可以是乘在output上，也可以是 copy n个插入buffer\n",
    "        # 预测正确和错误也可以 不断调整 更新的权重\n",
    "\n",
    "        nd_eval_acc.append(right_predict / (1+index))\n",
    "        if index > nd_eval_num:\n",
    "            break\n",
    "        pbar.update()\n",
    "    print(\" 总数为：\", nd_eval_num+2 ,\" 预测成功为：\", right_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ND_TestNet_End_Plot():\n",
    "    plt.plot(nd_eval_acc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_run():\n",
    "    TestNet_Init('load') # 训练\n",
    "    TestNet_Eval() # 预测\n",
    "    ND_TestNet_Eval_And_Train() # 加入新数据微调\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "\n",
    "def train_run():\n",
    "    TestNet_Init('train') # 训练\n",
    "    TestNet_Eval() # 预测\n",
    "    ND_TestNet_Eval_And_Train() # 加入新数据微调\n",
    "    plt.show()\n",
    "    \n",
    "def just_train():\n",
    "    TestNet_Init('train') # 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestNet_Init('load') # 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestNet_Eval(eval_num=10) # 预测TestNet_Eval() # 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新数据集测试与微调\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3147 [00:00<41:02,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/3147 [00:01<36:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3147 [00:02<34:31,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/3147 [00:02<36:37,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/3147 [00:03<38:19,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/3147 [00:04<36:31,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/3147 [00:04<36:59,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/3147 [00:05<36:51,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/3147 [00:06<37:06,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3147 [00:07<36:54,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/3147 [00:07<37:33,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/3147 [00:08<40:40,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 总数为： 10  预测成功为： 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ND_TestNet_Eval_And_Train(nd_eval_num = 10) # 加入新数据微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ND_TestNet_End_Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
